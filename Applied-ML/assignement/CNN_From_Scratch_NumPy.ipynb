{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d3c97a",
   "metadata": {},
   "source": [
    "# CNN From Scratch using NumPy\n",
    "\n",
    "**Goal:** Build and train a simple Convolutional Neural Network (CNN) from scratch (no deep learning libraries) using a toy image dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc46de",
   "metadata": {},
   "source": [
    "## 1. Import Required Library\n",
    "\n",
    "We only use **NumPy** to understand the core mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4f50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5f5c6",
   "metadata": {},
   "source": [
    "## 2. Generate Toy Dataset\n",
    "\n",
    "We create 8×8 grayscale images:\n",
    "- Class 0: vertical line\n",
    "- Class 1: horizontal line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25645428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_toy_data(n_samples=200):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        img = np.zeros((8, 8))\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            col = np.random.randint(1, 7)\n",
    "            img[:, col] = 1\n",
    "            y.append(0)\n",
    "        else:\n",
    "            row = np.random.randint(1, 7)\n",
    "            img[row, :] = 1\n",
    "            y.append(1)\n",
    "\n",
    "        X.append(img)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = generate_toy_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569eb6b",
   "metadata": {},
   "source": [
    "## 3. Convolution Layer\n",
    "\n",
    "Performs a **sliding window dot-product** using a 3×3 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269761d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv2D:\n",
    "    def __init__(self, filter_size=3):\n",
    "        self.filter = np.random.randn(filter_size, filter_size) * 0.1\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.last_x = x\n",
    "        h, w = x.shape\n",
    "        f = self.filter.shape[0]\n",
    "        out = np.zeros((h - f + 1, w - f + 1))\n",
    "\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                region = x[i:i+f, j:j+f]\n",
    "                out[i, j] = np.sum(region * self.filter)\n",
    "        return out\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        f = self.filter.shape[0]\n",
    "        d_filter = np.zeros_like(self.filter)\n",
    "\n",
    "        for i in range(d_out.shape[0]):\n",
    "            for j in range(d_out.shape[1]):\n",
    "                region = self.last_x[i:i+f, j:j+f]\n",
    "                d_filter += d_out[i, j] * region\n",
    "\n",
    "        self.filter -= lr * d_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df7912",
   "metadata": {},
   "source": [
    "## 4. ReLU Activation\n",
    "\n",
    "Introduces non-linearity by zeroing negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ca7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.mask = x > 0\n",
    "        return x * self.mask\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        return d_out * self.mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53c772",
   "metadata": {},
   "source": [
    "## 5. Fully Connected Layer\n",
    "\n",
    "Maps extracted features to class scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab05b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dense:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.W = np.random.randn(in_features, out_features) * 0.1\n",
    "        self.b = np.zeros(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x @ self.W + self.b\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        dW = self.x[:, None] @ d_out[None, :]\n",
    "        db = d_out\n",
    "        dx = self.W @ d_out\n",
    "\n",
    "        self.W -= lr * dW\n",
    "        self.b -= lr * db\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bce11",
   "metadata": {},
   "source": [
    "## 6. Softmax & Loss\n",
    "\n",
    "Softmax converts scores to probabilities.\n",
    "Cross-entropy measures classification loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b36051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x))\n",
    "    return e / np.sum(e)\n",
    "\n",
    "def cross_entropy(pred, target):\n",
    "    return -np.log(pred[target] + 1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60c423",
   "metadata": {},
   "source": [
    "## 7. Training the CNN\n",
    "\n",
    "Training includes:\n",
    "- Forward pass\n",
    "- Loss computation\n",
    "- Backward pass (gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7167a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6955, Accuracy: 0.53\n",
      "Epoch 2, Loss: 0.6750, Accuracy: 0.59\n",
      "Epoch 3, Loss: 0.6017, Accuracy: 0.85\n",
      "Epoch 4, Loss: 0.4403, Accuracy: 0.96\n",
      "Epoch 5, Loss: 0.3057, Accuracy: 0.96\n",
      "Epoch 6, Loss: 0.2369, Accuracy: 0.96\n",
      "Epoch 7, Loss: 0.2021, Accuracy: 0.96\n",
      "Epoch 8, Loss: 0.1830, Accuracy: 0.96\n",
      "Epoch 9, Loss: 0.1716, Accuracy: 0.96\n",
      "Epoch 10, Loss: 0.1645, Accuracy: 0.96\n",
      "Epoch 11, Loss: 0.1599, Accuracy: 0.96\n",
      "Epoch 12, Loss: 0.1567, Accuracy: 0.96\n",
      "Epoch 13, Loss: 0.1544, Accuracy: 0.96\n",
      "Epoch 14, Loss: 0.1528, Accuracy: 0.96\n",
      "Epoch 15, Loss: 0.1516, Accuracy: 0.96\n",
      "Epoch 16, Loss: 0.1508, Accuracy: 0.96\n",
      "Epoch 17, Loss: 0.1501, Accuracy: 0.96\n",
      "Epoch 18, Loss: 0.1495, Accuracy: 0.96\n",
      "Epoch 19, Loss: 0.1491, Accuracy: 0.96\n",
      "Epoch 20, Loss: 0.1488, Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv = Conv2D()\n",
    "relu = ReLU()\n",
    "fc = Dense(36, 2)\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        out = conv.forward(X[i])\n",
    "        out = relu.forward(out)\n",
    "        out = out.flatten()\n",
    "        out = fc.forward(out)\n",
    "        probs = softmax(out)\n",
    "\n",
    "        loss += cross_entropy(probs, y[i])\n",
    "        if np.argmax(probs) == y[i]:\n",
    "            correct += 1\n",
    "\n",
    "        grad = probs\n",
    "        grad[y[i]] -= 1\n",
    "\n",
    "        grad = fc.backward(grad, lr)\n",
    "        grad = grad.reshape(6, 6)\n",
    "        grad = relu.backward(grad)\n",
    "        conv.backward(grad, lr)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss/len(X):.4f}, Accuracy: {correct/len(X):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9f9f3",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "- You implemented a CNN **entirely from scratch**\n",
    "- Learned how convolution, ReLU, dense layers and backprop work\n",
    "- Ideal for **conceptual clarity and exams** ✅\n",
    "\n",
    "**Next steps:** Add pooling, multiple filters or visualize feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2244fb33",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Add pooling layer and improve training loopclass MaxPool2D:\n",
    "def __init__(self, pool_size=2, stride=2):\n",
    "    self.pool_size = pool_size\n",
    "    self.stride = stride\n",
    "    \n",
    "def forward(self, input):\n",
    "    self.input = input\n",
    "    batch_size, channels, height, width = input.shape\n",
    "    out_height = (height - self.pool_size) // self.stride + 1\n",
    "    out_width = (width - self.pool_size) // self.stride + 1\n",
    "    output = np.zeros((batch_size, channels, out_height, out_width))\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        for c in range(channels):\n",
    "            for i in range(out_height):\n",
    "                for j in range(out_width):\n",
    "                    h_start = i * self.stride\n",
    "                    h_end = h_start + self.pool_size\n",
    "                    w_start = j * self.stride\n",
    "                    w_end = w_start + self.pool_size\n",
    "                    output[b, c, i, j] = np.max(input[b, c, h_start:h_end, w_start:w_end])\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641eb20",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
